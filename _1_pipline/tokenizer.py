from transformers import AutoTokenizer, AutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)
encoding = tokenizer( "æˆ‘ä»¬å¾ˆé«˜å…´å‘æ‚¨å±•ç¤ºğŸ¤— Transformers åº“ã€‚" )
print(encoding)

pt_batch = tokenizer(
    ["æˆ‘ä»¬éå¸¸é«˜å…´å‘æ‚¨å±•ç¤º ğŸ¤— Transformers åº“ã€‚" , "æˆ‘ä»¬å¸Œæœ›æ‚¨ä¸è¦è®¨åŒå®ƒã€‚"],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="pt",
)
model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)
pt_outputs = pt_model(**pt_batch)
print(pt_outputs)

from torch import nn
pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)
print(pt_predictions)

from transformers import AutoConfig
my_config = AutoConfig.from_pretrained("distilbert/distilbert-base-uncased", n_heads=12)

from transformers import AutoModel
my_model = AutoModel.from_config(my_config)